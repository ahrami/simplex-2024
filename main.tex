\documentclass[a4paper,article,14pt]{extarticle}
\usepackage{styles}
\usepackage{amsmath}

\let\phi = \varphi
\let\epsilon = \varepsilon

\title{Симплекс Метод}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Линейное программирование}

Задача линейного программирования (ЛП) состоит в том, что нам необходимо максимизировать или минимизировать некоторый линейный функционал на многомерном пространстве при заданных линейных ограничениях.

\subsection{Линейный функционал}

Линейный функционал еще называется линейной формой, 1-формой, ковектором и ковариантным вектором.

Линейный функционал это линейное отображение, действующее из векторного пространства над полем в это же поле.

В алгебре и геометрии обычно используют название линейная форма, потому что чаще идет речь о конечномерных векторных пространствах, а в функциональном анализе линейный функционал, потому что там часто отображение именно над множествами функций.

Рациональные или вещественные множества это примеры полей.
Элементы поля называются скалярами.

Векторное пространство так же называется линейным пространством или линеалом.
Векторное пространство задается над полем.

Погожев определял линеал как множество объектов произвольной природы для которых определены сложение и умножение на число.
Никаких полей у нас не вводилось.

Отображение называется линейным когда оно удовлетворяет двум свойствам линейности:
\begin{equation}
    \begin{aligned}
        f(a + b) & = f(a) + f(b) \\
        f(\lambda a) & = \lambda f(a)
    \end{aligned}
\end{equation}

\subsection{Геометрическое представление задачи ЛП}

Симплекс --- это многомерное обобщение треугольника.
Другое его название --- n-мерный тетраэдр.
Симплекс --- это выпуклая оболочка \(n+1\) точек афинного пространства размерности как минимум \(n\), которые не лежат в подпространстве размерности \(n-1\) (афинно независимы).

Вообще говоря каждое из линейных неравенств на переменные ограничивает полупространство в соответствующем линеале.
В результате все неравенства ограничивают выпуклый многогранник.

Линейный функционал порождает гиперплоскость.
Гиперплоскость это подпространство, размерность которого на 1 меньше исходного пространства.

Требуется найти такую гиперплоскость, чтобы значение функционала было максимальным (или минимальным) и чтобы гиперплоскость пересекала многогранник хотя бы в одной точке.

Гиперплоскость задается одним вектором и этим вектором будет вектор \(n = \frac c {|c|}\). Это вектор самого быстрого изменения целевой функции и называется градиентом.
Еще для задания гиперплоскости нужна координата или же точка.

\subsection{Обозначения для математического представления}

\begin{itemize}
    \item Целевая функция (ЦФ) обозначается \(z\).
    \item Вектор коэффициентов целевой функции будем обозначать через \(c\).
    \item Вектор переменных \(x\).
    \item Вектор переменных двойственной задачи \(y\).
\end{itemize}

Вещи относящиеся к решению будем отмечать звездочкой:

\begin{itemize}
    \item Оптимальное решение: \(x^*\), \(y^*\).
    \item Значение задачи: \(z^*\), \(\overline z^*\)
\end{itemize}

Векторы у нас вертикальные, запись в строчку использует транспонирование.

\subsection{Математическое описание задачи ЛП}

Прямая задача максимизации в стандартной форме:
\begin{equation} \label{eq:primal_max}
    \begin{aligned}
        \max z & = \max c^Tx \\
        Ax & \le b \\
        x & \ge 0
    \end{aligned}
\end{equation}

% Можно писать еще так, но мы не будем:
% \begin{equation}
%     z = \langle c,x \rangle
%     , \quad
%     z \rightarrow \max
% \end{equation}

У нас \(m\) ограничений и \(n\) переменных.
\begin{equation}
    \begin{gathered}
        \begin{aligned}
            x & = (x_1, x_2, \ldots, x_n)^T \\
            c & = (c_1, c_2, \ldots, c_n)^T \\
            b & = (b_1, b_2, \ldots, b_m)^T
        \end{aligned} \\
        A
        = \{a_{ij}\}_{i,j = 1}^{m,n}
        =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        % = \begin{bmatrix}a_1 \\ a_2 \\ \vdots \\ a_n\end{bmatrix}
        % = [a^1, a^2, \ldots, a^n]
    \end{gathered}
\end{equation}

Другая раскрытая запись задачи ЛП для того чтобы думать:
\begin{equation}
    \begin{gathered}
        \max z = \max (c_1x_1 + c_2x_2 + \ldots + c_nx_n) \\
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        \begin{pmatrix}
            x_1 \\ x_2 \\ \vdots \\ x_n
        \end{pmatrix}
        \le
        \begin{pmatrix}
            b_1 \\ b_2 \\ \vdots \\ b_m
        \end{pmatrix}
        \\
        (x_1, x_2, \ldots, x_n)^T \ge 0
    \end{gathered}
\end{equation}

\newpage

\section{Двойственность}

Если честно, я бы дал это в самом начале, как такой разгон перед симплексом.
То есть если мы даем теорию ЛП, то и двойственность сразу надо, а потом уже алгоритмы решения.

\subsection{Двойственная задача для стандартной задачи максимизации}

В английском используются термины primal и dual.
На русском будем говорить прямая и двойственная.

Двойственная задача для стандартной задачи максимизации (\ref{eq:primal_max}):
\begin{equation} \label{dual_max}
    \begin{aligned}
        \min \overline z & = \min b^Ty \\
        A^Ty & \ge c \\
        y & \ge 0
    \end{aligned}
\end{equation}

В двойственной задаче у нас наоборот \(m\) переменных и \(n\) ограничений
\begin{equation}
    \begin{gathered}
        y = (y_1, y_2, \ldots, y_m)^T \\
        A^T =
        \begin{pmatrix}
            a_{11} & a_{21} & \ldots & a_{m1} \\
            a_{12} & a_{22} & \ldots & a_{m2} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{1n} & a_{2n} & \ldots & a_{mn}
        \end{pmatrix}
    \end{gathered}
\end{equation}

Более раскрытая запись для того чтобы думать:
\begin{equation}
    \begin{gathered}
        \min \overline z = \min (b_1y_1 + b_2y_2 + \ldots + b_my_m) \\
        \begin{pmatrix}
            a_{11} & a_{21} & \ldots & a_{m1} \\
            a_{12} & a_{22} & \ldots & a_{m2} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{1n} & a_{2n} & \ldots & a_{mn}
        \end{pmatrix}
        \begin{pmatrix}
            y_1 \\ y_2 \\ \vdots \\ y_m
        \end{pmatrix}
        \ge
        \begin{pmatrix}
            c_1 \\ c_2 \\ \vdots \\ c_n
        \end{pmatrix}
        \\
        (y_1, y_2, \ldots, y_m)^T \ge 0
    \end{gathered}
\end{equation}

\subsection{Теоремы двойственности}

\begin{equation}
    \begin{gathered}
        c^T x \le b^T y \\
        c^T x^* = b^T y^*
    \end{gathered}
\end{equation}

\(x*\) называется оптимальным решением, а значение целевой функции при нем называется значением задачи.

\subsection{Двойственность задачи ЛП в общем, стандартном и каноническом виде}

Прямая задача максимизации в общем виде:
\begin{equation}
    \begin{gathered}
        \max z = \max c^T x \\
        \begin{aligned}
            a_ix & \le b_i, \quad i = \overline{1, m_1} \\
            a_ix & = b_i, \quad i = \overline{m_1 + 1, m} \\
            x_j & \ge 0, \quad j = \overline{1, n_1} \\
            x_j & \in R, \quad j = \overline{n_1 + 1, n} \\
        \end{aligned}
    \end{gathered}
\end{equation}

Двойственная к ней:
\begin{equation}
    \begin{gathered}
    \min \overline z = \min b^T y \\
        \begin{aligned}
            (a^j)^Ty & \ge c_j, \quad j = \overline{1, n_1} \\
            (a^j)^Ty & = c_j, \quad j = \overline{n_1 + 1, n} \\
            y_i & \ge 0, \quad i = \overline{1, m_1} \\
            y_i & \in R, \quad i = \overline{m_1 + 1, m} \\
        \end{aligned}
    \end{gathered}
\end{equation}

Частный случай прямой задачи при котором она находится в стандартном виде означает что \(m_1 = m\) и \(n_1 = n\).
При таких значениях все ограничения являются неравенствами и у всех переменных есть ограничение на знак.
\begin{equation}
    \begin{gathered}
        \max z = \max c^T x \\
        \begin{aligned}
            a_ix & \le b_i, \quad i = \overline{1, m} \\
            x_j & \ge 0, \quad j = \overline{1, n} \\
        \end{aligned}
    \end{gathered}
\end{equation}

Двойственная задача к этой стандартной задаче будет тоже иметь все ограничения в виде неравенств и будет иметь ограничения на знак для переменных.
\begin{equation}
    \begin{gathered}
    \min \overline z = \min b^T y \\
        \begin{aligned}
            (a^j)^Ty & \ge c_j, \quad j = \overline{1, n} \\
            y_i & \ge 0, \quad i = \overline{1, m} \\
        \end{aligned}
    \end{gathered}
\end{equation}

Частный случай прямой задачи при котором она находится в каноническом виде означает что \(m_1 = 0\) и \(n_1 = n\).
При таких значениях все ограничения являются равенствами и у всех переменных есть ограничение на знак.
\begin{equation}
    \begin{gathered}
        \max z = \max c^T x \\
        \begin{aligned}
            a_ix & = b_i, \quad i = \overline{1, m} \\
            x_j & \ge 0, \quad j = \overline{1, n} \\
        \end{aligned}
    \end{gathered}
\end{equation}

Двойственная задача к этой канонической задаче будет иметь все ограничения в виде неравенств и не будет иметь ограничений на знак для переменных.
\begin{equation}
    \begin{gathered}
    \min \overline z = \min b^T y \\
        \begin{aligned}
            (a^j)^Ty & \ge c_j, \quad j = \overline{1, n} \\
            y_i & \in R, \quad i = \overline{1, m} \\
        \end{aligned}
    \end{gathered}
\end{equation}

\subsection{Представление двойственной задачи. Оптимальное решение двойственной задачи.}

Что такое вообще представление двойственной задачи.
Типа математическое?

Оптимальное решение двойственной задачи это типа оно выводится з прямой безо всякого алгоритма?
если так то было бы круто и если эта вся теория не зависит от симплекс метода то ее можно всю дать либо в самом начале перед симплекс методом, либо дать очень обзорно хоть вначале хоть в конце, раз у нас фокус то все таки на симплекс методе а не на ЛП в целом.

Я уверен ПМИшники про двойственность уже всё знают и нет особого смысла застревать на двойственноти.
Но если тут есть какие нибудь супер важные доказательства то мб и стоит их показать, хоть и не подробно.

Посмотрим сколько будет получаться по симплексу, и если будем чувствовать что успеваем то добавим в рассказ и про двойственность.

Все равно странно что нас просят двойственность в симплекс методе.

\newpage

\section{Основы симплекс метода}

Это метод решения задачи ЛП.
Это численный метод решения задачи ЛП [Гейл].

Он истекает из графического метода решения и из факта что оптимальное решение будет находиться в краевой точке множества которое задано нашими ограничениями.
Краевая точка это такая точка множества которая не принадлежит ни одному отрезку множества.

Граничная точка может лежать на ребре а краевые это только вершины.

Симплекс метод --- алгоритм решения оптимизационной задачи линейного программирования путем перебора вершин выпуклого многогранника в многомерном пространстве.

Сущность метода: построение последовательности базисных решений, на которой монотонно убывает (возрастает) линейный функционал до ситуации, когда выполняются необходимые и достаточные условия локальной оптимальности [Википедия].

В работе Канторовича 1939 впервые были изложены принципы отрасли которую потом назвали линейным программированием.

\subsection{Принцип симплекс метода}

Принцип симплекс метода состоит в том что мы выбираем одну вершину многогранника и перемещаемся по ребрам в другие вершины в сторону увеличения функционала.

Когда такой переход невозможен считается что оптимальное значение найдено (либо его нет).

Симплекс метод можно поделить на две основные фазы:

\begin{enumerate}
    \item Нахождение исходной вершины множества допустимых решений,
    \item Последовательный переход от одной вершины к другой, ведущий к оптимизации значения целевой функции.
\end{enumerate}

Из-за того что в некоторых случаях нахождение исходной вершины тривиально, симплекс метод бывает однофазным и двухфазным.
То есть в тривиальном случае первую фазу опускаем.
Тривиальным случаем может быть когда 0 --- допустимое решение

\subsection{Симплекс таблицы}

Симплексная таблица (СТ) - основной элемент вычислительной процедуры симплекс метода.
Симплексная таблица представляет собой таблицу коэффициентов диагональной формы, построенной для канонической задачи максимизации [Кузютин].
Из-за того что она диагональная, она соответствует базисному решению рассматриваемой системы линейных уравнений.

\subsection{Допустимость}

Симплексная таблица называется прямо-допустимой если \(b \ge 0\).
Симплексная таблица называется двойственно допустимой если \(c \ge 0\).
Симплексная таблица называется оптимальной если она одновременно и прямо-допустимая и двойственно допустимая.
Оптимальная СТ соответствует оптимальному базисному решению.

\subsection{Симплекс алгоритм}

Алгоритм начинается с прямо-допустимой симплексной таблицы.

\begin{enumerate}
    \item
        На первом шаге мы выбираем ведущий столбец.
        Выбираем столбец с минимальным отрицательным \(c\).
        Если таких нет, то оптимальное решение найдено.
    \item
        На втором шаге выбираем ведущую строку из строк у которых элемент этого столбца положительный.
        Если положительных нет, задача ЛП не омеет оптимального решения.
        Выбираем строку с минимальным \(b/a\).
    \item
        На третьем шаге превращаем ведущий элемент в 1 и остальные элементы столбца в 0 эквивалентными преобразованиями.
        То есть мы проводим процедуру Гаусса по приведению таблицы к диагональному виду по новому базису.
\end{enumerate}

\newpage

\section{Базисные решения}

Нам нужно показать:
\begin{itemize}
    \item Что такое базисное решение
    \item Как оно выводится, записывается и определяется математически
    \item Почему это именно вершины допустимого множества
    \item Как искать базисные решения
    \item Как искать именно допустимые базисные решения
\end{itemize}

\subsection{Определения}

\textit{Утверждение:} Если у системы линейных уравнений существует решение, у нее существует и базисное решение.

Базисным решениям соответствуют крайние точки множества допустимых решений.
Небазисные допустимые решения являются внутренними точками множества допустимых решений.

\textit{Утверждение:} Если задача ЛП имеет допустимое решение, то она имеет и допустимое базисное решение.

\textit{Утверждение:} Если задача ЛП имеет оптимальное решение, то она имеет и оптимальное базисное решение.

В силу этого утверждения симплекс метод оперирует только с базисными решениями.

\subsection{Объяснение}

Слабые переменные это \(s\).
Их количество равно количеству ограничений в случае перехода от стандартной задачи к канонической.

Удобно не забывать что мы работаем с пространством переменных \(x\), и в него не входят \(s\).

Добавлением слабой переменной к каждому неравенству при приведении стандартной задачи к канонической мы превращаем систему неравенств в линейно независимую систему уравнений.
С другой стороны, Гаусс нам тоже дает подмножество уравнений которые линейно независимы.

На каждом шаге мы разбиваем множество переменных на базисные и небазисные.
Небазисных переменных у нас столько, сколько размерность подпространства решений.
Имеется в виду опять подпространство исходного пространства переменных \(x\), то есть без слабых переменных.
А подпространство именно потому что в общей задаче могут быть уравнения.

Базисных переменных у нас соответственно столько, сколько у нас линейно независимых уравнений, и каждая базисная переменная соответствует отдельному линейно независимому уравнению.

Каждая слабая переменная пропорциональна расстоянию от решения до гиперплоскости соответствующего ограничения.
Это означает, что приравнивание слабой переменной к нулю будет гарантировать что мы будем касаться этого ограничения.
Приравнивание к нулю \(n\) (если размерность пространства решений равна \(n\)) таких переменных для линейно независимых ограничений гарантирует что мы будем в вершине множества допустимых решений.

Если же мы приравниваем к нулю одну из исходных переменных \(x\), тогда слабая \(s\) в этом неравенстве должна быть положительной, что значит мы не касаемся соответствующего ограничения.
Но не стоит забывать про ограничения на знак \(x \ge 0\), которого мы как раз и касаемся в этом случае. (В случаях, когда исходное ограничение равенство, или когда коэффициент при переменнной из \(x\) нулевой, у нас либо размерность меньше чем \(n\), либо ограничения линейно зависимы, поэтому ничего не ломается, я думаю).

Таким образом при обнулении набазисных переменных мы всегда касаемся \(n\) (если размерность пространства решений \(n\)) линейно независимых ограничений и оказываемся в какой-нибудь вершине множества допустимых решений.

\newpage

\section{Матричное представление симплекс таблиц}

Симплекс таблица это способ решения задачи ЛП и способ записи решения симплекс метода.

\subsection{Исходная таблица}

Стандартную задачу максимизации можно переписать в каноническом виде таким образом:

\begin{equation} \label{eq:matrix_form_1_phaze}
    \begin{gathered}
        \begin{bmatrix}
            1 & -c^T & 0 \\
            0 & A & E_m
        \end{bmatrix}
        \begin{bmatrix}
            z \\ x \\ s
        \end{bmatrix}
        =
        \begin{bmatrix}
            0 \\ b
        \end{bmatrix}
        \\
        z \rightarrow \max, \quad x \ge 0, \quad s \ge 0
    \end{gathered}
\end{equation}

Это и есть симплекс таблица в матричной форме.

\begin{itemize}
    \item \(s \ge 0\) --- новые переменные, называющиеся слабыми, дополняющие старые таким образом, что неравенства переходят в равенства.
    \item \(z\) --- это переменная которую необходимо максимизировать, значение нашей целевой функции.
    \item
        Еще в википедии есть что \(b \ge 0\).
        Это как раз условие того что симплекс алгоритм должен начинаться с прямо-допустимой таблицы.
\end{itemize}

Более раскрытая форма для понимания:

\setcounter{MaxMatrixCols}{20}
\begin{equation} \label{eq:matrix_form_1_phaze_expanded}
    \begin{pmatrix}
        1 & \vline & -c_1 & -c_2 & \ldots & -c_n & \vline & 0 & 0 & \ldots & 0 \\
        \hline
        0 & \vline & a_{11} & a_{12} & \ldots & a_{1n} & \vline & 1 & 0 & \ldots & 0 \\
        0 & \vline & a_{21} & a_{22} & \ldots & a_{2n} & \vline & 0 & 1 & \ldots & 0 \\
        \vdots & \vline & \vdots & \vdots & \ddots & \vdots & \vline & \vdots & \vdots & \ddots & \vdots \\
        0 & \vline & a_{m1} & a_{m2} & \ldots & a_{mn} & \vline & 0 & 0 & \ldots & 1 \\
    \end{pmatrix}
    \begin{pmatrix}
        z \\ \hline x_1 \\ x_2 \\ \vdots \\ x_n \\ \hline s_1 \\ s_2 \\ \vdots \\ s_m
    \end{pmatrix}
    =
    \begin{pmatrix}
        0 \\ \hline b_1 \\ b_2 \\ \vdots \\ b_m
    \end{pmatrix}
\end{equation}

% Нужно написать так же матрично преобразования этих симплекс таблиц.
%
% Пусть матрица
% \begin{equation}
%     H = 
%     \begin{bmatrix}
%         A & \vline & E_m
%     \end{bmatrix}
% \end{equation}
%
% Мы хотим преобразовать эту марицу так, чтобы все переменные \(x\) стали базисными.
% Базисных переменных в любой момент времени у нас будет \(m\).
% Небазисных переменных у нас в любой момент времени будет \(n\).
%
% Базисные переменные образуют диагональную матрицу.
% И каждой базисной переменной соответствует свое уравнение.
% Базисная переменная принимает значение \(b\) потому что все небазисные переменные приравниваются к нулю, а базисные имеют нулевые коэффициенты в этой точке.

\subsection{Таблица с другим базисом}

Пусть матрица \(B\) состоит из столбцов матрицы \(
    \begin{bmatrix}
        A & \vline & E_m
    \end{bmatrix}
\), соответствующих базисным переменным.
Пусть также \(c_B\) это коэффициенты ЦФ, соответствующие этим переменным.

Тогда из исходной таблицы (\ref{eq:matrix_form_1_phaze}) можно получить таблицу для другого базиса:

\begin{equation} \label{eq:matrix_form_1_phaze_basis}
    \begin{bmatrix}
        1 & c_B^TB^{-1}A-c^T & c_B^TB^{-1} \\
        0 & B^{-1}A & B^{-1}
    \end{bmatrix}
    \begin{bmatrix}
        z \\ x \\ s
    \end{bmatrix}
    =
    \begin{bmatrix}
        c_B^TB^{-1}b \\ B^{-1}b
    \end{bmatrix}
\end{equation}

\subsection{Базисные переменные}

Что вообще из себя представляет матрица \(B^{-1}A\)?

Пусть переменная \(x_j\) находится в базисе на месте \(i\).
Тогда столбец матрицы \(B\) с индексом \(i\) равен столбцу \(a^j\):
\begin{equation}
    \begin{gathered}
        B = \begin{bmatrix}
            B^1 & \ldots & a^j & \ldots & B^m
        \end{bmatrix} \\
        B^i = a^j
    \end{gathered}
\end{equation}

Пусть матрица \(B^{-1}\) выглядит так:
\begin{equation}
    B^{-1} =
    \{\hat b_{ij}\}_{i,j=1}^{m,m}
    =
    \begin{bmatrix}
        \hat b_1 &
        \hat b_2 &
        \ldots &
        \hat b_m
    \end{bmatrix}
    =
    \begin{bmatrix}
        \hat b^1 &
        \hat b^2 &
        \ldots &
        \hat b^m
    \end{bmatrix}
\end{equation}

Матрица \(B^{-1}\) при умножении на столбец \(a^j\) превращает его в единичный.
Единица в нем стоит на месте \(i\):
\begin{equation}
    B^{-1}a^j = \begin{bmatrix}
        0 & \ldots & 1 & \ldots & 0
    \end{bmatrix} ^T
\end{equation}
\begin{equation}
    \begin{gathered}
        \hat b_i a^j = 1, \quad i = j \\
        \hat b_i a^j = 0, \quad i \ne j
    \end{gathered}
\end{equation}

Тогда \(B^{-1}A\) можно записать так:
\begin{equation}
    B^{-1}A =
    \begin{pmatrix}
        \hat b_1a^1 & \ldots & \hat b_1a^j & \ldots & \hat b_1a^n \\
        \vdots & & \vdots & & \vdots \\
        \hat b_ia^1 & \ldots & \hat b_ia^j & \ldots & \hat b_ia^n \\
        \vdots & & \vdots & & \vdots \\
        \hat b_ma^1 & \ldots & \hat b_ma^j & \ldots & \hat b_ma^n \\
    \end{pmatrix}
    =
    \begin{pmatrix}
        \hat b_1a^1 & \ldots & 0 & \ldots & \hat b_1a^n \\
        \vdots & & \vdots & & \vdots \\
        \hat b_ia^1 & \ldots & 1 & \ldots & \hat b_ia^n \\
        \vdots & & \vdots & & \vdots \\
        \hat b_ma^1 & \ldots & 0 & \ldots & \hat b_ma^n \\
    \end{pmatrix}
\end{equation}

Матрица \(B^{-1}\) при умножении на матрицу \(A\) превращает все столбцы соответствующие базисным переменным в единичные.
Очевидно, то же самое будет происходить и для переменных \(s\).
Столбцы, которые не соответствуют базисным переменным будут иметь всякие разные числа.

Таким образом эта операция, то есть умножение на \(B^{-1}\) эквивалентна использованию метода Гаусса (или же эквивалентных преобразований) в симплекс алгоритме.
А именно, она нам приводит матрицу \(
    \begin{bmatrix}
        A & \vline & E_m
    \end{bmatrix}
\) к трапецевидной (или диагональной) форме по базисным переменным.

\subsection{Таблица в развернутом виде}

Перепишем таблицу (\ref{eq:matrix_form_1_phaze_basis}) в развернутом виде:

\begin{equation} \label{eq:c_b_hat}
    \hat c_B =
    c_B^TB^{-1} =
    \begin{pmatrix}
        c_B^T \hat b^1 &
        c_B^T \hat b^2 &
        \ldots &
        c_B^T \hat b^m
    \end{pmatrix}
\end{equation}
\begin{equation} \label{eq:matrix_form_1_phaze_basis_expanded}
    \begin{pmatrix}
        1 & \vline & c_B^TB^{-1} a^1-c_1 & \ldots & c_B^TB^{-1} a^n-c_n & \vline & \hat c_B_1 & \ldots & \hat c_B_m \\
        \hline
        0 & \vline & \hat b_1a^1 & \ldots & \hat b_1a^n & \vline & \hat b_{11} & \ldots & \hat b_{1m} \\
        0 & \vline & \hat b_2a^1 & \ldots & \hat b_2a^n & \vline & \hat b_{21} & \ldots & \hat b_{2m} \\
        \vdots & \vline & \vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
        0 & \vline & \hat b_ma^1 & \ldots & \hat b_ma^n & \vline & \hat b_{m1} & \ldots & \hat b_{mm} \\
    \end{pmatrix}
    \begin{pmatrix}
        z \\ \hline x_1 \\ x_2 \\ \vdots \\ x_n \\ \hline s_1 \\ s_2 \\ \vdots \\ s_m
    \end{pmatrix}
    =
    \begin{pmatrix}
        \hat c_B b \\ \hline \hat b_1 b \\ \hat b_2 b \\ \vdots \\ \hat b_m b
    \end{pmatrix}
\end{equation}

\subsection{Верхняя строка таблицы}

Строка \(
\begin{pmatrix}
    c_B^TB^{-1} a^1-c_1 & \ldots & c_B^TB^{-1} a^n-c_n & \vline & \hat c_B_1 & \ldots & \hat c_B_m
\end{pmatrix}
\) будет иметь нули на позициях соответствующим базисным переменным.

Мы уже выяснили что \(B^{-1}a^i\) превращает столбец в единичный если переменная \(x_i\) является базисной. Поэтому умножение этого произведения на \(c_B^T\) слева дает нам коэффициент ЦФ этой базисной переменной \(x_i\), и дальнейшее вычитание опять этого коэффициента обнуляет соответствующий элемент в строке.

Для переменных \(s\) всё еще проще, оно аналогично только вместо матрицы \(A\) у нас матрица \(E_m\), а изначальные коэффициенты уже равны нулю, поэтому вычитание опущено.

% Пусть \(x'\) базисные а \(x''\) небазисные.
%
% \(Ax + s = b \Leftrightarrow Bx' + Dx'' = b \Leftrightarrow x' + B^{-1}Dx'' = B^{-1}b\).
%
% \(z - c^Tx = 0\).
%
% \(c_B^TB^{-1}Ax + c_B^TB^{-1}s = c_B^TB^{-1}b\).

Таким образом, на каждом шаге \(m\) столбцов таблицы (\ref{eq:matrix_form_1_phaze_basis_expanded}), соответствующие базисным переменным являются линейно независимыми единичными столбцами.

\subsection{Условия оптимальности и допустимости}

Когда в верхней строчке в таблице (\ref{eq:matrix_form_1_phaze_basis_expanded}) нет отрицательных элементов, не считая элемента из правой части, оптимальное решение найдено, и записано в правой части уравнения.

Эта таблица прямо-допустима когда в правой части нет отрицательных элементов не считая первого.

% \section{Алгоритм решения с ограниченными переменными}
% Я не понимаю что это значит...
% Целочисленный что ли?

\newpage

\section{Источники}

\begin{enumerate}
    \item Конспект-книжка Кузютина Дениса Вячеславовича
    \item Гейл
    \item Таха
    \item Ашманов
    \item Ху
    \item Схрейвер
    \item Васильев
    \item Интернет
\end{enumerate}

\end{document}
