\documentclass[a4paper,article,14pt]{extarticle}
\usepackage{styles}
\usepackage{amsmath}

\let\phi = \varphi
\let\epsilon = \varepsilon

\title{Симплекс Метод}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\specialsection{Введение}

\begin{enumerate}
    \item \textit{Что такое основы симплекс метода?}
    \item \textit{У него есть основы?}
    \item \textit{Или это про основы ЛП.}
    \item \textit{Ну про ЛП мы не будем слишком много рассказывать, потому что наверное все всё уже про него знают и мы просто дадим за 0 секунд математическое описание ЛП и начнем про то как это решать.}
\end{enumerate}

\section{Линейное программирование}

Задача ЛП состоит в том, что необходимо максимизировать или минимизировать некоторый линейный функционал на многомерном пространстве при заданных линейных ограничениях.

\subsection{Линейный функционал}

Линейный функционал еще называется линейной формой, 1-формой, ковектором и ковариантным вектором.

Линейный функционал это линейное отображение, действующее из векторного пространства над полем в это же поле.

В алгебре и геометрии обычно используют название линейная форма, потому что чаще идет речь о конечномерных векторных пространствах, а в функциональном анализе линейный функционал, потому что там часто отображение именно над множествами функций.

Рациональные или вещественные множества это примеры полей.
Элементы поля называются скалярами.

Векторное пространство так же называется линейным пространством или линеалом.
Векторное пространство задается над полем.

Погожев определял линеал как множество объектов произвольной природы для которых определены сложение и умножение на число.
Никаких полей у нас не вводилось.

Отображение называется линейным когда оно удовлетворяет двум свойствам линейности:

\begin{gather}
    f(a + b) = f(a) + f(b) \\
    f(\lambda a) = \lambda f(a)
\end{gather}

\subsection{Геометрическое представление задачи ЛП}

Симплекс --- это многомерное обобщение треугольника.
Другое его название --- n-мерный тетраэдр.
Симплекс --- это выпуклая оболочка \(n+1\) точек афинного пространства размерности как минимум \(n\), которые не лежат в подпространстве размерности \(n-1\) (афинно независимы).

Вообще говоря каждое из линейных неравенств на переменные ограничивает полупространство в соответствующем линеале.
В результате все неравенства ограничивают выпуклый многогранник.

Линейный функционал порождает гиперплоскость.
Гиперплоскость это подпространство, размерность которого на 1 меньше исходного пространства.

Требуется найти такую гиперплоскость, чтобы значение функционала было максимальным (или минимальным) и чтобы гиперплоскость пересекала многогранник хотя бы в одной точке.

Гиперплоскость задается одним вектором и этим вектором будет вектор \(n = \frac c {|c|}\). Это вектор самого быстрого изменения целевой функции и называется градиентом.
Еще для задания гиперплоскости нужна координата или же точка.

\section{Математическое описание задачи ЛП}

\subsection{Обозначения}

На английском primal и dual.
На русском будем говорить прямая и двойственная.

\begin{itemize}
    \item Целевая функция (ЦФ) обозначается \(z\).
    \item Вектор коэффициентов целевой функции будем обозначать через \(c\).
    \item Вектор переменных \(x\).
    \item Вектор переменных двойственной задачи \(y\).
\end{itemize}

Вещи относящиеся к решению будем отмечать звездочкой:

\begin{itemize}
    \item Оптимальное решение: \(x^*\), \(y^*\).
    \item Значение задачи: \(z^*\), \(\overline z^*\)
\end{itemize}

Векторы у нас вертикальные, запись в строчку использует транспонирование.

\subsection{Прямая задача}

Прямая задача максимизации в стандартной форме:

\begin{equation}
    \max z = \max c^Tx
\end{equation}
\begin{gather}
    Ax \le b \\
    x \ge 0
\end{gather}

% Еще в википедии есть что \(b \ge 0\), но такого больше нигде нет и непонятно зачем вообще это.

% Можно писать еще так, но мы не будем:
% \begin{equation}
%     z = \langle c,x \rangle
%     , \quad
%     z \rightarrow \max
% \end{equation}

У нас \(m\) ограничений и \(n\) переменных.
\begin{gather}
    x = (x_1, x_2, \ldots, x_n)^T \\
    c = (c_1, c_2, \ldots, c_n)^T \\
    b = (b_1, b_2, \ldots, b_m)^T \\
    A =
    \begin{pmatrix}
        a_{11} & a_{12} & \ldots & a_{1n} \\
        a_{21} & a_{22} & \ldots & a_{2n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m1} & a_{m2} & \ldots & a_{mn}
    \end{pmatrix}
    % = \begin{bmatrix}a_1 \\ a_2 \\ \vdots \\ a_n\end{bmatrix}
    % = [a^1, a^2, \ldots, a^n]
    = \{a_{ij}\}_{i,j = 1}^{m,n}
\end{gather}

Другая раскрытая запись задачи ЛП для того чтобы думать:
\begin{gather}
    \max z = \max (c_1x_1 + c_2x_2 + \ldots + c_nx_n) \\
    \begin{pmatrix}
        a_{11} & a_{12} & \ldots & a_{1n} \\
        a_{21} & a_{22} & \ldots & a_{2n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m1} & a_{m2} & \ldots & a_{mn}
    \end{pmatrix}
    \begin{pmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_n
    \end{pmatrix}
    \le
    \begin{pmatrix}
        b_1 \\ b_2 \\ \vdots \\ b_m
    \end{pmatrix}
    \\
    (x_1, x_2, \ldots, x_n)^T \ge 0
\end{gather}

\subsection{Двойственная задача}

Двойственная задача для стандартной задачи максимизации:

\begin{equation}
    \min \overline z = \min b^Ty
\end{equation}
\begin{gather}
    A^Ty \ge c \\
    y \ge 0
\end{gather}

В двойственной задаче у нас наоборот \(m\) переменных и \(n\) ограничений
\begin{gather}
    y = (y_1, y_2, \ldots, y_m)^T \\
    A^T =
    \begin{pmatrix}
        a_{11} & a_{21} & \ldots & a_{m1} \\
        a_{12} & a_{22} & \ldots & a_{m2} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{1n} & a_{2n} & \ldots & a_{mn}
    \end{pmatrix}
\end{gather}

Более раскрытая запись для того чтобы думать:

\begin{gather}
    \min \overline z = \min (b_1y_1 + b_2y_2 + \ldots + b_my_m) \\
    \begin{pmatrix}
        a_{11} & a_{21} & \ldots & a_{m1} \\
        a_{12} & a_{22} & \ldots & a_{m2} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{1n} & a_{2n} & \ldots & a_{mn}
    \end{pmatrix}
    \begin{pmatrix}
        y_1 \\ y_2 \\ \vdots \\ y_m
    \end{pmatrix}
    \ge
    \begin{pmatrix}
        c_1 \\ c_2 \\ \vdots \\ c_n
    \end{pmatrix}
    \\
    (y_1, y_2, \ldots, y_m)^T \ge 0
\end{gather}


\subsection{Усиленная постановка задачи ЛП}

Стандартную задачу максимизации можно записать так:

\begin{equation}
    \begin{bmatrix}
        1 & -c^T & 0 \\
        0 & A & E_m
    \end{bmatrix}
    \begin{bmatrix}
        z \\ x \\ s
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\ b
    \end{bmatrix}
    , \guad
    z \rightarrow \max
\end{equation}

\begin{itemize}
    \item \(s \ge 0\) --- новые переменные, дополняющие старые таким образом, что неравенство переходит в равенство.
    \item \(z\) --- это переменная которую необходимо максимизировать, значение нашей целевой функции.
\end{itemize}

Более раскрытая форма для понимания:

\begin{equation}
    \begin{pmatrix}
        1 & -c_1 & -c_2 & \ldots & -c_n & 0 & 0 & \ldots & 0 \\
        0 & a_{11} & a_{12} & \ldots & a_{1n} & 1 & 0 & \ldots & 0 \\
        0 & a_{21} & a_{22} & \ldots & a_{2n} & 0 & 1 & \ldots & 0 \\
        \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots \\
        0 & a_{m1} & a_{m2} & \ldots & a_{mn} & 0 & 0 & \ldots & 1 \\
    \end{pmatrix}
    \begin{pmatrix}
        z \\ x_1 \\ x_2 \\ \vdots \\ x_n \\ s_1 \\ s_2 \\ \vdots \\ s_m
    \end{pmatrix}
    =
    \begin{pmatrix}
        0 \\ b_1 \\ b_2 \\ \vdots \\ b_m
    \end{pmatrix}
\end{equation}

\section{Двойственность}

Если честно, я бы дал это в самом начале, как такой разгон перед симплексом.
То есть если мы даем теорию ЛП, то и двойственность сразу надо, а потом уже алгоритмы решения.
Но если мы ничего доказывать отсюда не будем, то чтобы не переписывать несколько раз уравнения двойственности на доске, может быть лучше дать это здесь чтобы перед алгоритмом для двойственной задачи оно было написано и не стиралось уже.

\subsection{Теоремы двойственности}

\[
c^T x <= b^T y

c^T x* = b^T y*
\]

\(x*\) называется оптимальным решением, а значение целевой функции при нем называется значенем задачи.

Вообще говоря приведение ограничений к равенствам дает нам задачу ЛП в стандартной (канонической) форме.
И наверное оно еще может называться усиленной постановкой задачи ЛП.

\subsection{Двойственность задачи ЛП в общем виде}

Прямая задача в общем виде:
\begin{gather}
    a_ix \le b_i, i = \overline{1, m_1} \\
    a_ix = b_i, i = \overline{m_1 + 1, m} \\
    x_j \ge 0, j = \overline{1, n_1} \\
    x_j \in R, j = \overline{n_1 + 1, n} \\
\end{gather}

Двойственная к ней:
\begin{gather}
    (a^j)^Ty \ge c_j, j = \overline{1, n_1} \\
    (a^j)^Ty = c_j, j = \overline{n_1 + 1, n} \\
    y_i \ge 0, i = \overline{1, m_1} \\
    y_i \in R, i = \overline{m_1 + 1, m} \\
\end{gather}

\subsection{Представление двойственной задачи. Оптимальное решение двойственной задачи.}

Что такое вообще представление двойственной задачи.
Типа математическое?

Оптимальное решение двойственной задачи это типа оно выводится з прямой безо всякого алгоритма?
если так то было бы круто и если эта вся теория не зависит от симплекс метода то ее можно всю дать либо в самом начале перед симплекс методом, либо дать очень обзорно хоть вначале хоть в конце, раз у нас фокус то все таки на симплекс методе а не на ЛП в целом.

Я уверен ПМИшники про двойственность уже всё знают и нет особого смысла застревать на двойственноти.
Но если тут есть какие нибудь супер важные доказательства то мб и стоит их показать, хоть и не подробно.

Посмотрим сколько будет получаться по симплексу, и если будем чувствовать что успеваем то добавим в рассказа и про двойственность.

Все равно странно что нас просят двойственность в симплекс методе.

\section{Основы симплекс метода}

Это метод решения задачи ЛП.

Он истекает из графического метода решения и из факта что оптимальное решение будет находиться в краевой точке множества которое задано нашими ограничениями.
Краевая точка это ..
И почему вообще так.

Симплекс метод - алгоритм решения оптимизационной задачи линейного программирования путем перебора вершин выпуклого многогранника в многомерном пространстве.

Сущность метода: построение базисных решений, на которых монотонно убывает линейный функционал до ситуации, когда выполняются необходимые условия локальной оптимальности.

В работе Канторовича 1939 впервые были изложены принципы отрасли которую потом назвали линейным программированием.

\subsection{Принцип симплекс метода}

Принцип симплекс метода состоит в том что мы выбираем одну вершину многогранника и перемещаемся по ребрам в другие вершины в сторону увеличения функционала.

Когда такой переход невозможен считается что оптимальное значение найдено.

Симплекс метода можно поделить на две основные фазы:

1. нахождение исходной вершины множества допустимых решений,
2. последовательный переход от одной вершины к другой, ведущий к оптимизации значения целевой функции.

Из за того что в некоторых случаях нахождение исходной вершины тривиально, симплекс метод бывает однофазным и двухфазным.
То есть в тривиальном случае первую фазу опускаем.
Тривиальным случаем может быть когда 0 - допустимое решение

\section{Базисные решения}

Что?
Базисное решение это решение с которого мы начинаем наши расчеты.

\section{Матричное представление симплекс таблиц}

Что такое вообще симплекс таблицы..
Симплекс таблица это способ записи решения симплекс метода.

\section{Условия оптимальности и допустимости}

\section{Алгоритм решения с ограниченными переменными}

Я не совсем понимаю что это значит
То есть помимо исходной матрицы A у нас еще есть другие ограничения для каждой переменной?

На моей памяти мы обычно только относительно нуля огрвничиваем их, делаем не отрицательные или не положительные.
Но если ограничения более разнообразные бывают и для этого сильно меняется математика и сообветственно алгоритм то плохо дело.

\end{document}
